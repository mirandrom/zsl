{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import datasets as hfds\n",
    "\n",
    "import olmo\n",
    "from olmo.config import TrainConfig\n",
    "from olmo.util import clean_opt\n",
    "from olmo.torch_util import seed_all\n",
    "from olmo.data import build_train_dataloader, IterableDataset\n",
    "\n",
    "from olmo.optim import build_optimizer\n",
    "from olmo.config import TrainConfig\n",
    "from olmo.checkpoint import load_state_dict\n",
    "from olmo.model import OLMo\n",
    "\n",
    "from zsl_config import ZSL_DIR_OUT_OLMO, ZSL_DIR_ANALYSIS, ZSL_DIR_DATA\n",
    "\n",
    "from typing import Union, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MODEL_CLASS = 'olmo'\n",
    "DATASET = 'c4_en_val'\n",
    "ANALYSIS_NAME = 'per_token_change_in_loss-dt=1'\n",
    "\n",
    "RUNS = [\n",
    "        '1028-rmsnorm-14m',\n",
    "        '1028-rmsnorm-37m',\n",
    "        '1028-rmsnorm-78m',\n",
    "        '1028-rmsnorm-144m',\n",
    "        '1028-rmsnorm-285m',\n",
    "        '1028-rmsnorm-472m',\n",
    "    ]\n",
    "\n",
    "VERBOSE = True\n",
    "OVERWRITE = False\n",
    "\n",
    "OUT_DIR = ZSL_DIR_ANALYSIS / ANALYSIS_NAME\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measure change in losses for $\\Delta t=1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded batch with shape: torch.Size([512, 1024])\n",
      "Original batch size: 64\n"
     ]
    }
   ],
   "source": [
    "def load_train_batch(run, step, *args) -> TrainConfig:\n",
    "    yaml_path = ZSL_DIR_OUT_OLMO / run / 'config.yaml'\n",
    "    cfg = TrainConfig.load(yaml_path, [clean_opt(s) for s in args])\n",
    "    # Set `global_indices_file` to shared path\n",
    "    cfg.data.global_indices_file = ZSL_DIR_OUT_OLMO / \"train_data/global_indices.npy\"\n",
    "    # Load single batch instead of distributed \n",
    "    cfg.device_train_batch_size = cfg.global_train_batch_size\n",
    "    seed_all(cfg.seed)\n",
    "    train_loader = build_train_dataloader(cfg)\n",
    "    assert isinstance(train_loader.dataset, IterableDataset)\n",
    "\n",
    "    global_train_examples_seen_this_epoch = cfg.global_train_batch_size * step\n",
    "    train_loader.dataset.start_index = global_train_examples_seen_this_epoch\n",
    "    batch = next(iter(train_loader))\n",
    "    return batch['input_ids']\n",
    "\n",
    "def get_device_bsz(run):\n",
    "    yaml_path = ZSL_DIR_OUT_OLMO / run / 'config.yaml'\n",
    "    cfg = TrainConfig.load(yaml_path)\n",
    "    bsz = cfg.device_train_batch_size\n",
    "    return bsz\n",
    "\n",
    "if VERBOSE:\n",
    "    batch = load_train_batch(RUNS[0],1)\n",
    "    print(f\"Loaded batch with shape: {batch.shape}\")\n",
    "    print(f\"Original batch size: {get_device_bsz(RUNS[0])}\")\n",
    "    del batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(dataloader): 244\n",
      "batch shape: torch.Size([4, 1024])\n",
      "batch device: cpu\n"
     ]
    }
   ],
   "source": [
    "tokenized_eval_data = ZSL_DIR_DATA / f'tokenized/{MODEL_CLASS}-{DATASET}'\n",
    "assert tokenized_eval_data.exists()\n",
    "\n",
    "def get_dataloader(bsz: int = 4, device: str = 'cpu'):\n",
    "    dataset = hfds.load_from_disk(tokenized_eval_data)\n",
    "    dataset.set_format(type='torch', columns=['input_ids'])\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=bsz, shuffle=False, \n",
    "                                             pin_memory=device != 'cpu', \n",
    "                                             pin_memory_device=device)\n",
    "    return dataloader\n",
    "\n",
    "if VERBOSE:\n",
    "    dataloader = get_dataloader(device='cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"len(dataloader): {len(dataloader)}\")\n",
    "    print(f\"batch shape: {next(iter(dataloader))['input_ids'].shape}\")\n",
    "    print(f\"batch device: {next(iter(dataloader))['input_ids'].device}\")\n",
    "    del dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps for run 1028-rmsnorm-14m: [1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536, 131072, 262144]\n",
      "==================== MODEL ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mila/m/mirceara/1.workspace/zsl/pretraining/olmo/olmo/checkpoint.py:317: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(path, map_location=map_location)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLMo(\n",
      "  (transformer): ModuleDict(\n",
      "    (wte): Embedding(50304, 256)\n",
      "    (emb_drop): Dropout(p=0.0, inplace=False)\n",
      "    (ln_f): RMSLayerNorm()\n",
      "    (blocks): ModuleList(\n",
      "      (0-3): 4 x OLMoSequentialBlock(\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (act): SwiGLU()\n",
      "        (attn_out): Linear(in_features=256, out_features=256, bias=False)\n",
      "        (ff_out): Linear(in_features=128, out_features=256, bias=False)\n",
      "        (rotary_emb): RotaryEmbedding()\n",
      "        (att_proj): Linear(in_features=256, out_features=768, bias=False)\n",
      "        (ff_proj): Linear(in_features=256, out_features=256, bias=False)\n",
      "        (attn_norm): RMSLayerNorm()\n",
      "        (ff_norm): RMSLayerNorm()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================== OPTIMIZER ====================\n",
      "AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.95)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-05\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.00126\n",
      "    lr: 0.000144144\n",
      "    max_grad_norm: 1.0\n",
      "    max_grad_norm_ratio: None\n",
      "    maximize: False\n",
      "    param_names: ['_fsdp_wrapped_module.transformer.blocks.0.att_proj.weight', '_fsdp_wrapped_module.transformer.blocks.0.attn_out.weight', '_fsdp_wrapped_module.transformer.blocks.0.ff_out.weight', '_fsdp_wrapped_module.transformer.blocks.0.ff_proj.weight', '_fsdp_wrapped_module.transformer.blocks.1.att_proj.weight', '_fsdp_wrapped_module.transformer.blocks.1.attn_out.weight', '_fsdp_wrapped_module.transformer.blocks.1.ff_out.weight', '_fsdp_wrapped_module.transformer.blocks.1.ff_proj.weight', '_fsdp_wrapped_module.transformer.blocks.2.att_proj.weight', '_fsdp_wrapped_module.transformer.blocks.2.attn_out.weight', '_fsdp_wrapped_module.transformer.blocks.2.ff_out.weight', '_fsdp_wrapped_module.transformer.blocks.2.ff_proj.weight', '_fsdp_wrapped_module.transformer.blocks.3.att_proj.weight', '_fsdp_wrapped_module.transformer.blocks.3.attn_out.weight', '_fsdp_wrapped_module.transformer.blocks.3.ff_out.weight', '_fsdp_wrapped_module.transformer.blocks.3.ff_proj.weight']\n",
      "    sharded: True\n",
      "    weight_decay: 0.1\n",
      "\n",
      "Parameter Group 1\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.95)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-05\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.00126\n",
      "    lr: 0.000144144\n",
      "    max_grad_norm: 1.0\n",
      "    max_grad_norm_ratio: None\n",
      "    maximize: False\n",
      "    param_names: ['_fsdp_wrapped_module.transformer.wte.weight']\n",
      "    sharded: True\n",
      "    weight_decay: 0.0\n",
      ")\n",
      "==================== PARAMS ====================\n",
      "Param:  transformer.wte.weight torch.Size([50304, 256]) torch.float32 cuda:0\n",
      "Optim:  transformer.wte.weight torch.Size([50304, 256]) torch.float32 cuda:0\n",
      "................................................................................\n",
      "Param:  transformer.blocks.0.attn_out.weight torch.Size([256, 256]) torch.float32 cuda:0\n",
      "Optim:  transformer.blocks.0.attn_out.weight torch.Size([256, 256]) torch.float32 cuda:0\n",
      "................................................................................\n",
      "Param:  transformer.blocks.0.ff_out.weight torch.Size([256, 128]) torch.float32 cuda:0\n",
      "Optim:  transformer.blocks.0.ff_out.weight torch.Size([256, 128]) torch.float32 cuda:0\n",
      "................................................................................\n",
      "Param:  transformer.blocks.0.att_proj.weight torch.Size([768, 256]) torch.float32 cuda:0\n",
      "Optim:  transformer.blocks.0.att_proj.weight torch.Size([768, 256]) torch.float32 cuda:0\n",
      "................................................................................\n",
      "Param:  transformer.blocks.0.ff_proj.weight torch.Size([256, 256]) torch.float32 cuda:0\n",
      "Optim:  transformer.blocks.0.ff_proj.weight torch.Size([256, 256]) torch.float32 cuda:0\n",
      "................................................................................\n",
      "Param:  transformer.blocks.1.attn_out.weight torch.Size([256, 256]) torch.float32 cuda:0\n",
      "Optim:  transformer.blocks.1.attn_out.weight torch.Size([256, 256]) torch.float32 cuda:0\n",
      "................................................................................\n",
      "Param:  transformer.blocks.1.ff_out.weight torch.Size([256, 128]) torch.float32 cuda:0\n",
      "Optim:  transformer.blocks.1.ff_out.weight torch.Size([256, 128]) torch.float32 cuda:0\n",
      "................................................................................\n",
      "Param:  transformer.blocks.1.att_proj.weight torch.Size([768, 256]) torch.float32 cuda:0\n",
      "Optim:  transformer.blocks.1.att_proj.weight torch.Size([768, 256]) torch.float32 cuda:0\n",
      "................................................................................\n",
      "Param:  transformer.blocks.1.ff_proj.weight torch.Size([256, 256]) torch.float32 cuda:0\n",
      "Optim:  transformer.blocks.1.ff_proj.weight torch.Size([256, 256]) torch.float32 cuda:0\n",
      "................................................................................\n",
      "Param:  transformer.blocks.2.attn_out.weight torch.Size([256, 256]) torch.float32 cuda:0\n",
      "Optim:  transformer.blocks.2.attn_out.weight torch.Size([256, 256]) torch.float32 cuda:0\n",
      "................................................................................\n",
      "Param:  transformer.blocks.2.ff_out.weight torch.Size([256, 128]) torch.float32 cuda:0\n",
      "Optim:  transformer.blocks.2.ff_out.weight torch.Size([256, 128]) torch.float32 cuda:0\n",
      "................................................................................\n",
      "Param:  transformer.blocks.2.att_proj.weight torch.Size([768, 256]) torch.float32 cuda:0\n",
      "Optim:  transformer.blocks.2.att_proj.weight torch.Size([768, 256]) torch.float32 cuda:0\n",
      "................................................................................\n",
      "Param:  transformer.blocks.2.ff_proj.weight torch.Size([256, 256]) torch.float32 cuda:0\n",
      "Optim:  transformer.blocks.2.ff_proj.weight torch.Size([256, 256]) torch.float32 cuda:0\n",
      "................................................................................\n",
      "Param:  transformer.blocks.3.attn_out.weight torch.Size([256, 256]) torch.float32 cuda:0\n",
      "Optim:  transformer.blocks.3.attn_out.weight torch.Size([256, 256]) torch.float32 cuda:0\n",
      "................................................................................\n",
      "Param:  transformer.blocks.3.ff_out.weight torch.Size([256, 128]) torch.float32 cuda:0\n",
      "Optim:  transformer.blocks.3.ff_out.weight torch.Size([256, 128]) torch.float32 cuda:0\n",
      "................................................................................\n",
      "Param:  transformer.blocks.3.att_proj.weight torch.Size([768, 256]) torch.float32 cuda:0\n",
      "Optim:  transformer.blocks.3.att_proj.weight torch.Size([768, 256]) torch.float32 cuda:0\n",
      "................................................................................\n",
      "Param:  transformer.blocks.3.ff_proj.weight torch.Size([256, 256]) torch.float32 cuda:0\n",
      "Optim:  transformer.blocks.3.ff_proj.weight torch.Size([256, 256]) torch.float32 cuda:0\n",
      "................................................................................\n"
     ]
    }
   ],
   "source": [
    "def load_model(run: str, step: int, device=\"cuda\", overrides: Optional[list] = None):\n",
    "    ckpt_dir = ZSL_DIR_OUT_OLMO / run / f\"step{step}-unsharded\"\n",
    "    overrides = overrides or []\n",
    "    overrides.append(f\"model.init_device={device}\")\n",
    "    cfg = TrainConfig.load(\n",
    "        ckpt_dir / \"config.yaml\", validate_paths=False, overrides=overrides\n",
    "    )\n",
    "    model = OLMo(cfg.model, init_params=False)\n",
    "    state_dict = load_state_dict(ckpt_dir, \"model.pt\", map_location=device)\n",
    "    model.load_state_dict(state_dict)\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_optimizer(\n",
    "    model, run: str, step: int, device=\"cuda\", overrides: Optional[list] = None\n",
    "):\n",
    "    ckpt_dir = ZSL_DIR_OUT_OLMO / run / f\"step{step}-unsharded\"\n",
    "    overrides = overrides or []\n",
    "    overrides.append(f\"model.init_device={device}\")\n",
    "    cfg = TrainConfig.load(\n",
    "        ckpt_dir / \"config.yaml\", validate_paths=False, overrides=overrides\n",
    "    )\n",
    "    optimizer = build_optimizer(cfg, model)\n",
    "    state_dict = load_state_dict(ckpt_dir, \"optim.pt\", map_location=device)\n",
    "    optimizer.load_state_dict(state_dict)\n",
    "    return optimizer\n",
    "\n",
    "\n",
    "def get_model_steps(run: str):\n",
    "    ckpts_dir = ZSL_DIR_OUT_OLMO / run\n",
    "    return sorted(\n",
    "        [\n",
    "            int(d.name.replace(\"step\", \"\").replace(\"-unsharded\", \"\"))\n",
    "            for d in ckpts_dir.glob(\"step[1-9]*-unsharded\")\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "if VERBOSE:\n",
    "    run = RUNS[0]\n",
    "    steps = get_model_steps(run)\n",
    "    print(f\"steps for run {run}: {steps}\")\n",
    "    step = steps[5]\n",
    "\n",
    "    print(\"=\" * 20, \"MODEL\", \"=\" * 20)\n",
    "    model = load_model(run, step, device=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(model)\n",
    "\n",
    "    print(\"=\"*20, \"OPTIMIZER\", \"=\"*20)\n",
    "    optimizer = load_optimizer(model, run, step, device='cpu')\n",
    "    print(optimizer)\n",
    "\n",
    "    print(\"=\"*20, \"PARAMS\", \"=\"*20)\n",
    "    for n,p in model.named_parameters():\n",
    "        o = optimizer.state[p]\n",
    "        print(\"Param: \", n, p.shape, p.dtype, p.device)\n",
    "        print(\"Optim: \", n, o['exp_avg'].shape, o['exp_avg'].dtype, o['exp_avg'].device)\n",
    "        print('.'*80)\n",
    "        \n",
    "    del run, step, steps, model, n, p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1028-rmsnorm-472m][262144][262148][15][post-eval]\t\t\t\ta/zsl_scratch/analysis/per_token_change_in_loss-dt=1/1028-rmsnorm-472m/.eval-c4_en_val/step262144.pt\r"
     ]
    }
   ],
   "source": [
    "num_train_batches = 5\n",
    "bsz_eval = 64\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "overrides = [\"model.flash_attention=False\"] if device == \"cpu\" else []\n",
    "\n",
    "# train dataloader + cache tokens\n",
    "run = RUNS[0]\n",
    "train_batch_steps = [get_model_steps(run)[-1] + i for i in range(num_train_batches)]\n",
    "train_batches = {}\n",
    "for batch_step in train_batch_steps:\n",
    "    out_path = OUT_DIR / f\"tokens/train-batch={batch_step}.pt\"\n",
    "    if out_path.exists() and not OVERWRITE:\n",
    "        batch = torch.load(out_path, weights_only=True)\n",
    "    else:\n",
    "        batch = load_train_batch(run, batch_step)\n",
    "        out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        torch.save(batch, out_path)\n",
    "\n",
    "    microbsz = get_device_bsz(RUNS[0])\n",
    "    num_microbatches = batch.shape[0] // microbsz\n",
    "    train_batches[batch_step] = batch\n",
    "\n",
    "# eval dataloader + cache tokens\n",
    "eval_dataloader = get_dataloader(bsz=bsz_eval, device=device)\n",
    "eval_tokens = [b[\"input_ids\"].cpu() for b in eval_dataloader]\n",
    "eval_tokens = torch.cat(eval_tokens, dim=0)\n",
    "out_path = OUT_DIR / f\"tokens/eval-{DATASET}.pt\"\n",
    "out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "torch.save(eval_tokens, out_path)\n",
    "\n",
    "amp_ctx = torch.amp.autocast(device, dtype=torch.bfloat16)\n",
    "inf_ctx = torch.inference_mode()\n",
    "\n",
    "for run in RUNS:\n",
    "    out_dir = OUT_DIR / run\n",
    "    out_dir.mkdir(exist_ok=True, parents=False)\n",
    "\n",
    "    steps = get_model_steps(run)\n",
    "    for t in steps:\n",
    "        # set model to None for lazy loading\n",
    "        model = None\n",
    "\n",
    "        # 1. init eval losses\n",
    "        path_eval_init = out_dir / f\".eval-{DATASET}/step{t}.pt\"\n",
    "        print(f\"[{run}][{t}] {path_eval_init}\", end=\"\\r\")\n",
    "        if not path_eval_init.exists() or (path_eval_init.exists() and OVERWRITE):\n",
    "            path_eval_init.parent.mkdir(parents=True, exist_ok=True)\n",
    "            model = load_model(run, t, overrides=overrides, device=device)\n",
    "            model = model.to(torch.bfloat16)\n",
    "            model.eval()\n",
    "            losses = []\n",
    "            with inf_ctx, amp_ctx:\n",
    "                for i, batch in enumerate(eval_dataloader):\n",
    "                    print(f\"[{run}][{t}][{i}][init-eval]\\t\\t\\t\", end=\"\\r\")\n",
    "                    batch = batch[\"input_ids\"].to(device)\n",
    "                    input_ids = batch[:, :-1].contiguous()\n",
    "                    labels = batch[:, 1:].flatten().to(device)\n",
    "                    logits = model(input_ids).logits.flatten(0, 1)\n",
    "                    _losses = F.cross_entropy(logits, labels, reduction=\"none\")\n",
    "                    losses.append(_losses.detach().cpu())\n",
    "                    del logits, _losses            \n",
    "            torch.save(torch.cat(losses, dim=0), path_eval_init)\n",
    "\n",
    "        for bs in train_batch_steps:\n",
    "            print(f\"[{run}][{t}][{bs}]\\t\\t\\t\", end=\"\\r\")\n",
    "            batch_dir = out_dir / f\"train-batch={bs}\"\n",
    "\n",
    "            # 0.1 skip batch dir if already done and no overwrite\n",
    "            path_train_init = batch_dir / f\"init/train/step{t}.pt\"\n",
    "            path_train_post = batch_dir / f\"post/train/step{t}.pt\"\n",
    "            spath_eval_init = batch_dir / f\"init/eval-{DATASET}/step{t}.pt\"\n",
    "            path_eval_post = batch_dir / f\"post/eval-{DATASET}/step{t}.pt\"\n",
    "            skip_batch_dir = all(\n",
    "                [\n",
    "                    path_train_init.exists(),\n",
    "                    path_train_post.exists(),\n",
    "                    path_eval_post.exists(),\n",
    "                    spath_eval_init.exists(),\n",
    "                    not OVERWRITE,\n",
    "                ]\n",
    "            )\n",
    "            if skip_batch_dir:\n",
    "                continue\n",
    "\n",
    "            # 0.2 load model and optimizer\n",
    "            if model is None:\n",
    "                model = load_model(run, t, overrides=overrides, device=device)\n",
    "                model = model.to(torch.bfloat16)\n",
    "            optimizer = load_optimizer(model, run, t, device=device)\n",
    "            optimizer.zero_grad()\n",
    "            for pg in optimizer.param_groups:\n",
    "                if pg['lr'] == 0:\n",
    "                    assert run.startswith('1028-rmsnorm'), f\"Learning rate hack might be wrong here.\"\n",
    "                    pg['lr'] = pg['initial_lr']\n",
    "\n",
    "            # 0.3 load train microbatches\n",
    "            batch = train_batches[bs]\n",
    "            global_batch_num_tokens = batch.shape[0] * (batch.shape[1] - 1)\n",
    "            microbsz = get_device_bsz(run)\n",
    "            num_microbatches = batch.shape[0] // microbsz\n",
    "            train_microbatch_dataloader = [\n",
    "                batch[i * microbsz : (i + 1) * microbsz].to(device)\n",
    "                for i in range(num_microbatches)\n",
    "            ]\n",
    "\n",
    "            # 1. init eval losses (symlink)\n",
    "            if spath_eval_init.exists() and OVERWRITE:\n",
    "                spath_eval_init.unlink()\n",
    "            if not spath_eval_init.exists():\n",
    "                spath_eval_init.parent.mkdir(parents=True, exist_ok=True)\n",
    "                spath_eval_init.symlink_to(path_eval_init)\n",
    "\n",
    "            # 2. init train losses (with backward pass and weight update for post losses)\n",
    "            losses = []\n",
    "            model.train()\n",
    "            for i, microbatch in enumerate(train_microbatch_dataloader):\n",
    "                print(f\"[{run}][{t}][{bs}][{i}][init-train]\\t\\t\\t\", end=\"\\r\")\n",
    "                input_ids = microbatch[:, :-1].to(device)\n",
    "                labels = microbatch[:, 1:].flatten().to(device)\n",
    "                with amp_ctx:\n",
    "                    logits = model(input_ids).logits.flatten(0, 1)\n",
    "                    _losses = F.cross_entropy(logits, labels, reduction=\"none\")\n",
    "                    loss = _losses.sum() / global_batch_num_tokens\n",
    "                loss.backward()\n",
    "                losses.append(_losses.detach().cpu())\n",
    "                del logits, _losses, loss\n",
    "            optimizer.step()\n",
    "            del optimizer\n",
    "            model.eval()\n",
    "            if not path_train_init.exists():\n",
    "                path_train_init.parent.mkdir(parents=True, exist_ok=True)\n",
    "                torch.save(torch.cat(losses, dim=0), path_train_init)\n",
    "\n",
    "            # 3. post train losses\n",
    "            if (not path_train_post.exists()) or (path_train_post.exists() and OVERWRITE):\n",
    "                path_train_post.parent.mkdir(parents=True, exist_ok=True)\n",
    "                losses = []\n",
    "                with inf_ctx, amp_ctx:\n",
    "                    for i, microbatch in enumerate(train_microbatch_dataloader):\n",
    "                        print(f\"[{run}][{t}][{bs}][{i}][post-train]\\t\\t\\t\", end=\"\\r\")\n",
    "                        input_ids = microbatch[:, :-1].to(device)\n",
    "                        labels = microbatch[:, 1:].flatten().to(device)\n",
    "                        logits = model(input_ids).logits.flatten(0, 1)\n",
    "                        _losses = F.cross_entropy(logits, labels, reduction=\"none\")\n",
    "                        losses.append(_losses.detach().cpu())\n",
    "                        del logits, _losses\n",
    "                torch.save(torch.cat(losses, dim=0), path_train_post)\n",
    "\n",
    "            # 4. post eval losses\n",
    "            if (not path_eval_post.exists()) or (path_eval_post.exists() and OVERWRITE):\n",
    "                path_eval_post.parent.mkdir(parents=True, exist_ok=True)\n",
    "                losses = []\n",
    "                with inf_ctx, amp_ctx:\n",
    "                    for i, batch in enumerate(eval_dataloader):\n",
    "                        print(f\"[{run}][{t}][{bs}][{i}][post-eval]\\t\\t\\t\", end=\"\\r\")\n",
    "                        batch = batch[\"input_ids\"].to(device)\n",
    "                        input_ids = batch[:, :-1].contiguous()\n",
    "                        labels = batch[:, 1:].flatten().to(device)\n",
    "                        logits = model(input_ids).logits.flatten(0, 1)\n",
    "                        _losses = F.cross_entropy(logits, labels, reduction=\"none\")\n",
    "                        losses.append(_losses.detach().cpu())\n",
    "                        del logits, _losses\n",
    "                torch.save(torch.cat(losses, dim=0), path_eval_post)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
